{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Mathematical and Numerical Physics\n",
    "### Numerical part 2\n",
    "#### Kevin Vonk, s1706896, _Dec 2020 - Jan 2021_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## General Part\n",
    "### Question 1\n",
    "#### a.\n",
    "Firstly, let us write out the component-wise product $\\boldsymbol{T} = \\boldsymbol{L'}\\boldsymbol{U'}$, where $i = 2, ..., N$,\n",
    "\\begin{align*}\n",
    "    t_{1,1} &= l'_{1,1} \\\\\n",
    "    t_{i, i-1} &= l'_{i, i-1} \\\\\n",
    "    t_{i, i} &= l'_{i, i-1} \\cdot u'_{i-1, i} + l'_{i, i} \\\\\n",
    "    t_{i-1, i} &= l'_{i-1, i-1} \\cdot u'_{i-1, i}.\n",
    "\\end{align*}\n",
    "\n",
    "Now that we have these expressions, we can define the form of $\\boldsymbol{L'}$ and $\\boldsymbol{U'}$ analogously to eq. (1.7) of the lecture notes,\n",
    "\\begin{equation*}\n",
    "    l'_{1, 1} = t_{1, 1}; \\; \\text{for} \\; i = 2, ..., N, \\; u'_{i-1, i} = \\frac{t_{i-1, 1}}{l'_{i-1, i-1}}; \\; l'_{i, i-1} = t_{i, i-1}; \\; l'_{i, i} = t_{i, i} - l'_{i, i-1} \\cdot u'_{i-1, i}.\n",
    "\\end{equation*}\n",
    "\n",
    "We still perform the forward subsitution as $\\boldsymbol{L'}\\boldsymbol{y} = \\boldsymbol{b}$ as in eq. (1.8) in the lecture notes,\n",
    "\\begin{equation*}\n",
    "    y_1 = \\frac{b_1}{l'_{1, 1}}; \\; \\text{for} \\; i = 2, ..., N \\; y_i = \\frac{b_i}{l'_{i, i}} - l'_{i, i-1}y_{i-1}.\n",
    "\\end{equation*}\n",
    "\n",
    "Finally, for the back subsitution step $\\boldsymbol{U}\\boldsymbol{x} = \\boldsymbol{y}$ we again follow the same procedure as in eq. (1.9) of the lecture notes,\n",
    "\\begin{equation*}\n",
    "    x_N = y_N; \\; \\text{for} \\; i = N, ..., 2 \\; x_{i-1} = y_{i-1} - u'_{i-1, i}x_i.\n",
    "\\end{equation*}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### b.\n",
    "_Case I_\n",
    "\n",
    "We can naively solve this system by writing out the two linear equations,\n",
    "\\begin{align*}\n",
    "    x_1 + x_2 &= 1 \\\\\n",
    "    x_1 + (1 + 10^{-10})x_2 &= 1.\n",
    "\\end{align*}\n",
    "\n",
    "Filling in one into the other yields,\n",
    "\\begin{align*}\n",
    "    1 - x_2 + (1 + 10^{-10})x_2 &= 1 \\\\\n",
    "    10^{-10}x_2 &= 0 \\\\\n",
    "    x_2 &= 0 \\\\\n",
    "    &\\rightarrow x_1 = 1.\n",
    "\\end{align*}\n",
    "\n",
    "So,\n",
    "\\begin{equation*}\n",
    "    \\vec{x} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}.\n",
    "\\end{equation*}\n",
    "\n",
    "_Case II_\n",
    "\n",
    "Similarly as above,\n",
    "\\begin{align*}\n",
    "    x_1 + x_2 &= 1 \\\\\n",
    "    x_1 + (1 + 10^{-10})x_2 &= 1 + 10^{-10}.\n",
    "\\end{align*}\n",
    "\n",
    "Again, filling in one into the other,\n",
    "\\begin{align*}\n",
    "    1 - x_2 + (1 + 10^{-10})x_2 &= 1 \\\\\n",
    "    10^{-10}x_2 &= 10^{-10} \\\\\n",
    "    x_2 &= 1 \\\\\n",
    "    &\\rightarrow x_1 = 0.\n",
    "\\end{align*}\n",
    "\n",
    "So,\n",
    "\\begin{equation*}\n",
    "    \\vec{x} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}.\n",
    "\\end{equation*}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### c.\n",
    "Before even having calculated anything I am certain this matrix is ill-conditioned, purely due to the $10^{-10}$ term present. Let us prove this however by computing the eigenvalues of this matrix,\n",
    "\\begin{align*}\n",
    "    \\begin{vmatrix}\n",
    "        1 - \\lambda & 1 \\\\\n",
    "        1 & 1 + 10^{-10} - \\lambda\n",
    "    \\end{vmatrix} &= 0 \\\\\n",
    "    (1 - \\lambda)(1 + 10^{-10} - \\lambda) - 1 &= 0 \\\\\n",
    "    \\lambda^2 -\\lambda(2 + 10^{-10}) + 10^{-10} &= 0 \\\\\n",
    "    \\lambda_\\pm = \\frac{2 + 10^{-10} \\pm \\sqrt{(2 + 10^{-10})^2 - 4*10^{-10}}}{2} &\\\\\n",
    "    \\lambda_\\pm = \\frac{2 + 10^{-10} \\pm \\sqrt{4 + 10^{-20}}}{2}. &\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now, these two eigenvalues turn out to be vastly different from one another, about an expected order of magnitude $10^{-10}$. Now, it doesn't yield anything by writing out these expressions further, nor is it easy and useful to simplify this further. We can however, give the approximate values:\n",
    "\\begin{align*}\n",
    "    \\lambda_{\\text{max}} \\approx 2; \\; \\lambda_{\\text{min}} \\approx 5\\cdot 10^{-11}.\n",
    "\\end{align*}\n",
    "\n",
    "Filling in these values into the expression for the condition number yields,\n",
    "\\begin{align*}\n",
    "    \\kappa \\approx \\frac{2}{5\\cdot 10^{-11}} \\approx 4\\cdot 10^{10}.\n",
    "\\end{align*}\n",
    "\n",
    "Given that $\\kappa$ should idealy lie around $1$, to say that this matrix is ill-conditioned is an understatement. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### d.\n",
    "What we have here is a nearly singular matrix ($\\begin{bmatrix}1 & 1 \\\\ 1 & 1\\end{bmatrix}$ is a fully singular matrix, and we are only $10^{-10}$ away from this in only a single element). We have already established that this problem is ill-conditioned, and indeed, when changing the independent variables only slightly (case I to case II), the dependent variable $\\vec{x}$ changes dramatically. From the definition of the condition number (eq. (1.13) of the lecture notes), we learn that it is related to the maximum relative error. Given that the condition number is in the order of $10^{10}$ for this problem, and assuming that for the uncertainty $\\delta$ of $b$ it holds that $\\delta < b$ (which is a more than reasonable assumption), the error is so incredibly large that the solution for $\\vec{x}$ is useless.\n",
    "\n",
    "Now, if $\\vec{b}$ were some inputs to a model and $\\vec{x}$ the output parameters, we can deduce from what has previously been stated that a tiny change in the input (possibly even rounding errors) will lead to a completely different output of the model. This leads us to conclude that convergence is (nearly) impossible (i.e. we will not find a solution to $\\vec{x} to a reasonable degree, if at all), or that the problem is ill-conditioned (i.e. the parameters that we need to work with cannot produce a satisfying result)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Question 2\n",
    "#### a."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}